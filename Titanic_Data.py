# -*- coding: utf-8 -*-
"""Untitled44.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qAskXoAMeaQFSRi_Cdn0bUJ3OfcXx8VW
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

from google.colab import files

uploaded = files.upload()

import io

data = pd.read_csv(io.BytesIO(uploaded['Titanic Train Data.csv']))

data.info()

data.columns

data.isnull().sum()

data.drop(['Cabin'],axis=1,inplace=True)

data['Age']=data['Age'].fillna(data['Age'].mean())

data.isnull().sum()

data.head()

data.drop(['Ticket','Name'],axis=1,inplace=True)

data.head()

final_df = data.copy()

columns=['Sex','Embarked']

def category_onehot_multcols(multcolumns):
    df_final=final_df
    i=0
    for fields in multcolumns:
        
        print(fields)
        df1=pd.get_dummies(final_df[fields],drop_first=True)
        
        final_df.drop([fields],axis=1,inplace=True)
        if i==0:
            df_final=df1.copy()
        else:
            
            df_final=pd.concat([df_final,df1],axis=1)
        i=i+1
       
        
    df_final=pd.concat([final_df,df_final],axis=1)
        
    return df_final

final_df=category_onehot_multcols(columns)

final_df.head()

x = final_df.drop(['Survived'],axis=1)
y = final_df['Survived']

x.head()

y.head()

final_df.info()

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()

model.fit(x_train,y_train)

y_pre=model.predict(x_test)

from sklearn.metrics import confusion_matrix,accuracy_score

confusion_matrix(y_test,y_pre)

accuracy_score(y_pre,y_test)

accuracy_score(y_pre,y_test)

from google.colab import files

uploaded = files.upload()

import io

data = pd.read_csv(io.BytesIO(uploaded['Titanic Test Data.csv']))

data.info()

data.columns

data.isnull().sum()

data.drop(['Cabin'],axis=1,inplace=True)

data['Age']= data['Age'].fillna(data['Age'].mean())

data.isnull().sum()

data.head()

data['Fare']= data['Fare'].fillna(data['Fare'].mean())

data.isnull().sum()

data.drop(['Name'],axis=1,inplace=True)

data.shape

test_data = data.copy()

test_data.head()

columns = ['Sex','Embarked']

def category_onehot_multcols(multcolumns):
    df_final=test_data
    i=0
    for fields in multcolumns:
        
        print(fields)
        df1=pd.get_dummies(test_data[fields],drop_first=True)
        
        test_data.drop([fields],axis=1,inplace=True)
        if i==0:
            df_final=df1.copy()
        else:
            
            df_final=pd.concat([df_final,df1],axis=1)
        i=i+1
       
        
    df_final=pd.concat([test_data,df_final],axis=1)
        
    return df_final

final_Testdf=category_onehot_multcols(columns)

final_Testdf.head()

final_Testdf.drop(['Ticket'],axis=1,inplace=True)

final_Testdf.columns

final_Testdf.head()

final_pre = model.predict(final_Testdf)

final_pre

pred = pd.DataFrame(final_pre)

pred

from sklearn.ensemble import RandomForestClassifier

kmodel = RandomForestClassifier()

kmodel.fit(x_train,y_train)
kmodel.predict(final_Testdf)

